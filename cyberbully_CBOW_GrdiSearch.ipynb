{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZZAsu1kYQ3JD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
        "import gensim\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "910ZCrJQQ3JG",
        "outputId": "5b453e54-142d-4ad8-a513-2de57b8796c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17152847, 22638920)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
        "Y = df.iloc[::,1].to_numpy()\n",
        "types = {'age':0,\n",
        "         'ethnicity':1,\n",
        "         'gender':2,\n",
        "         'not_cyberbullying':3,\n",
        "         'other_cyberbullying':4,\n",
        "         'religion':5}\n",
        "Y = [types[y] for y in Y]\n",
        "Y = np.reshape(Y, (len(Y),1))\n",
        "X = df.iloc[::,0].to_numpy()\n",
        "X = [''.join(item.lower() for item in x if item.isalpha() or item == \" \") for x in X]\n",
        "X = [x.split(\" \") for x in X] \n",
        "#X = [item for sublist in X for item in sublist]\n",
        "\n",
        "cbow = gensim.models.Word2Vec(\n",
        "            X,\n",
        "            size=50, # desired no. of features/independent variables\n",
        "            window=8, # context window size\n",
        "            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n",
        "            sg = 0, # 0 for cbow\n",
        "            hs = 0, # to enable negative sampling\n",
        "            negative = 10, # for negative sampling\n",
        "            cbow_mean = 1, # use the mean instead of the sum\n",
        "            workers= 32, # no.of cores\n",
        "            seed = 34) \n",
        "\n",
        "cbow.train(X, total_examples= len(X), epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoLfot8XQ3JI",
        "outputId": "07d2682a-2943-4ae6-f76a-345c607b4c6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47692, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def word_vector(tokens, size):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        try:\n",
        "            vec += cbow.wv[word].reshape((1, size))\n",
        "            count += 1.\n",
        "        except KeyError:  # handling the case where the token is not in vocabulary\n",
        "            continue\n",
        "    if count != 0:\n",
        "        vec /= count\n",
        "    return vec\n",
        "wordvec_arrays = np.zeros((len(X), 50)) \n",
        "for i in range(len(X)):\n",
        "    wordvec_arrays[i,:] = word_vector(X[i], 50)\n",
        "wordvec_df = pd.DataFrame(wordvec_arrays)\n",
        "wordvec_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQhWOlsfQ3JJ",
        "outputId": "58ab6009-2f28-4421-aeb2-1a2230626382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sk-learn model score:  0.646561364271736\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(wordvec_df, Y, test_size=0.30, random_state=0)\n",
        "X_train = X_train.values.tolist()\n",
        "X_test = X_test.values.tolist()\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(max_depth = 10, min_samples_split = 6, min_samples_leaf= 1, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "print(\"sk-learn model score: \", clf.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZpGsA2P-FBkz"
      },
      "outputs": [],
      "source": [
        "def display_top_ten(results):\n",
        "\n",
        "  results_df = pd.DataFrame(results)\n",
        "  results_df = results_df.sort_values(by=[\"rank_test_score\"])\n",
        "  results_df = results_df.set_index(\n",
        "      results_df[\"params\"].apply(lambda x: \"_\".join(str(val) for val in x.values()))\n",
        "      ).rename_axis(\"kernel\")\n",
        "  top = results_df[[ \"rank_test_score\", \"mean_test_score\", \"std_test_score\"]]\n",
        "\n",
        "  print(top[:10])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYmvGnpp5a6X",
        "outputId": "50c72e41-ffd6-4f09-a4ef-ebe72acf86b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model:  \n",
            " Max Depth =  10 \n",
            " Min Samples Split =  3 \n",
            " Min Samples Leaf =  4\n",
            "Best DT model score:  0.6467710371819961\n",
            "TOP 10 Models: \n",
            "\n",
            "         rank_test_score  mean_test_score  std_test_score\n",
            "kernel                                                   \n",
            "10_4_6                 1         0.637581        0.004405\n",
            "10_4_3                 1         0.637581        0.004405\n",
            "10_1_10                3         0.636952        0.004729\n",
            "10_1_3                 4         0.636742        0.004094\n",
            "10_4_10                5         0.636532        0.004512\n",
            "15_8_3                 6         0.636322        0.006316\n",
            "15_8_6                 6         0.636322        0.006316\n",
            "15_8_10                6         0.636322        0.006316\n",
            "10_1_6                 9         0.636023        0.004690\n",
            "10_8_10               10         0.635963        0.005283\n"
          ]
        }
      ],
      "source": [
        "dt = tree.DecisionTreeClassifier(random_state=42)\n",
        "DT = Pipeline([('dt', dt)])\n",
        "\n",
        "\n",
        "parameters = {\n",
        "              'dt__max_depth': [5, 10, 15],\n",
        "              'dt__min_samples_split': [3, 6, 10],\n",
        "              'dt__min_samples_leaf': [1, 4, 8]\n",
        "              }\n",
        "\n",
        "grid_DT = GridSearchCV(DT, parameters, verbose=0, return_train_score=True)\n",
        "grid_DT = grid_DT.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_par = grid_DT.best_estimator_.get_params()\n",
        "\n",
        "print(\"Best model: \",\n",
        "      '\\n Max Depth = ', best_par['dt__max_depth'],\n",
        "      '\\n Min Samples Split = ', best_par['dt__min_samples_split'],\n",
        "      '\\n Min Samples Leaf = ', best_par['dt__min_samples_leaf']\n",
        "      )\n",
        "\n",
        "best_score = grid_DT.score(X_test, y_test)\n",
        "print(\"Best DT model score: \", best_score)\n",
        "\n",
        "results = grid_DT.cv_results_\n",
        "print(\"TOP 10 Models: \\n\")\n",
        "display_top_ten(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxn-IzyrSrld",
        "outputId": "bbda6a05-c3c1-4098-ae9a-18ec72c93230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model:  \n",
            " Number of Estimators =  10\n",
            "Best RF model score:  0.7121190942130277\n",
            "TOP 10 Models: \n",
            "\n",
            "        rank_test_score  mean_test_score  std_test_score\n",
            "kernel                                                  \n",
            "10                    1         0.707525        0.005723\n",
            "5                     2         0.671460        0.005174\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier()\n",
        "\n",
        "RF = Pipeline([('rf', rf)])\n",
        "\n",
        "parameters = {\n",
        "              'rf__n_estimators': [5, 10]#, 15, 20]\n",
        "              }\n",
        "\n",
        "grid_RF = GridSearchCV(RF, parameters, verbose=0, return_train_score=True)\n",
        "grid_RF = grid_RF.fit(X_train, y_train.ravel())\n",
        "\n",
        "\n",
        "best_par = grid_RF.best_estimator_.get_params()\n",
        "\n",
        "print(\"Best model: \",\n",
        "      '\\n Number of Estimators = ', best_par['rf__n_estimators']\n",
        "      )\n",
        "\n",
        "best_score = grid_RF.score(X_test, y_test.ravel())\n",
        "print(\"Best RF model score: \", best_score)\n",
        "\n",
        "results = grid_RF.cv_results_\n",
        "print(\"TOP 10 Models: \\n\")\n",
        "display_top_ten(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7kVFblGFzlj",
        "outputId": "1b2044fc-2632-472a-ac05-5fdd692c75a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model:  \n",
            " Number of Estimators =  20\n",
            "Best BAG model score:  0.7172211350293543\n",
            "TOP 10 Models: \n",
            "\n",
            "        rank_test_score  mean_test_score  std_test_score\n",
            "kernel                                                  \n",
            "20                    1         0.721723        0.002221\n",
            "15                    2         0.713426        0.002094\n",
            "10                    3         0.699587        0.003836\n",
            "5                     4         0.670471        0.001834\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "bag = BaggingClassifier(tree.DecisionTreeClassifier()) #, max_samples=0.5, n_estimators=100)\n",
        "\n",
        "BAG = Pipeline([\n",
        "               ('bag', bag)])\n",
        "\n",
        "parameters = {'bag__n_estimators': [5, 10, 15, 20]}\n",
        "\n",
        "grid_BAG = GridSearchCV(BAG, parameters, verbose=0, return_train_score=True)\n",
        "grid_BAG = grid_BAG.fit(X_train, y_train.ravel())\n",
        "\n",
        "best_par = grid_BAG.best_estimator_.get_params()\n",
        "\n",
        "print(\"Best model: \",\n",
        "      '\\n Number of Estimators = ', best_par['bag__n_estimators']\n",
        "      )\n",
        "\n",
        "best_score = grid_BAG.score(X_test, y_test.ravel())\n",
        "print(\"Best BAG model score: \", best_score)\n",
        "\n",
        "results = grid_BAG.cv_results_\n",
        "print(\"TOP 10 Models: \\n\")\n",
        "display_top_ten(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29cud2BSF6yK",
        "outputId": "162c1be3-4d3b-4d45-8147-af90e0f13241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model:  \n",
            " Number of Estimators =  15 \n",
            " Learning Rate =  0.1\n",
            "Best AdaBoost model score:  0.715403969807101\n",
            "TOP 10 Models: \n",
            "\n",
            "           rank_test_score  mean_test_score  std_test_score\n",
            "kernel                                                     \n",
            "0.1_15                   1         0.717050        0.004917\n",
            "0.1_10                   2         0.706087        0.003312\n",
            "0.1_5                    3         0.675174        0.005082\n",
            "0.001_15                 4         0.621854        0.006746\n",
            "0.001_10                 5         0.621735        0.009139\n",
            "0.0001_15                6         0.620237        0.006861\n",
            "0.001_5                  7         0.618979        0.008762\n",
            "0.0001_10                8         0.618320        0.007437\n",
            "0.0001_5                 9         0.617092        0.007179\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier(tree.DecisionTreeClassifier()) \n",
        "\n",
        "ADA = Pipeline([\n",
        "               ('ada', ada)])\n",
        "\n",
        "\n",
        "parameters = {\n",
        "              'ada__n_estimators': [5, 10, 15],\n",
        "              'ada__learning_rate' : [0.0001, 0.001, 0.1]\n",
        "              }\n",
        "\n",
        "grid_ADA = GridSearchCV(ADA, parameters, verbose=0, return_train_score=True)\n",
        "grid_ADA = grid_ADA.fit(X_train, y_train.ravel())\n",
        "\n",
        "\n",
        "best_par = grid_ADA.best_estimator_.get_params()\n",
        "\n",
        "print(\"Best model: \",\n",
        "      '\\n Number of Estimators = ', best_par['ada__n_estimators'],\n",
        "      '\\n Learning Rate = ', best_par['ada__learning_rate']\n",
        "      )\n",
        "\n",
        "best_score = grid_ADA.score(X_test, y_test.ravel())\n",
        "print(\"Best AdaBoost model score: \", best_score)\n",
        "\n",
        "results = grid_ADA.cv_results_\n",
        "print(\"TOP 10 Models: \\n\")\n",
        "display_top_ten(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZNyO9I3F61P",
        "outputId": "9a42aa5e-0099-4780-ece0-77eac9169188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Gradient Boosting Classifier model:  \n",
            " Number of Estimators =  15 \n",
            " Learning Rate =  0.1\n",
            "Best Gradient Boosting Classifier model score:  0.6922001677383282\n",
            "TOP 10 Models: \n",
            "\n",
            "           rank_test_score  mean_test_score  std_test_score\n",
            "kernel                                                     \n",
            "0.1_15                   1         0.689702        0.004033\n",
            "0.1_10                   2         0.676312        0.004801\n",
            "0.1_5                    3         0.655613        0.004680\n",
            "0.001_15                 4         0.609633        0.005062\n",
            "0.001_10                 5         0.592739        0.005289\n",
            "0.001_5                  6         0.528756        0.006894\n",
            "0.0001_15                7         0.253834        0.003191\n",
            "0.0001_10                8         0.246555        0.003748\n",
            "0.0001_5                 9         0.168045        0.000010\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "GBC = Pipeline([\n",
        "               ('gbc', GradientBoostingClassifier())])\n",
        "\n",
        "\n",
        "parameters = {\n",
        "              'gbc__n_estimators': [5, 10, 15],\n",
        "              'gbc__learning_rate' : [0.001, 0.1]              \n",
        "              }\n",
        "\n",
        "grid_GBC = GridSearchCV(GBC, parameters, verbose=0, return_train_score=True)\n",
        "grid_GBC = grid_GBC.fit(X_train, y_train.ravel())\n",
        "\n",
        "\n",
        "best_par = grid_GBC.best_estimator_.get_params()\n",
        "\n",
        "print(\"Best Gradient Boosting Classifier model: \",\n",
        "      '\\n Number of Estimators = ', best_par['gbc__n_estimators'],\n",
        "      '\\n Learning Rate = ', best_par['gbc__learning_rate']\n",
        "      )\n",
        "\n",
        "best_score = grid_GBC.score(X_test, y_test.ravel())\n",
        "print(\"Best Gradient Boosting Classifier model score: \", best_score)\n",
        "\n",
        "results = grid_GBC.cv_results_\n",
        "print(\"TOP 10 Models: \\n\")\n",
        "display_top_ten(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5bQHf183F633"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZQnRGCbjF66f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0IRY-ULJF684"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rM9qx45bF6_b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YV1YnsVZF7CL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Og--ZMTiAXI4"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "cyberbully_cbow_GS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "07429fcb4c504a0378980367d3c7fce80391802e4a36d1633a5a7bb6cd53a327"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}